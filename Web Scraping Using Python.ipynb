{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af2b80a1",
   "metadata": {},
   "source": [
    "# Introduction to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c759308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Tree to HTML\n",
    "\n",
    "html = '''\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Intro HTML</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <p>Hello World!</p>\n",
    "    <p>Enjoy DataCamp!</p>\n",
    "  </body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "951f2b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep it classy\n",
    "\n",
    "# HTML code string\n",
    "html = '''\n",
    "<html>\n",
    "  <body>\n",
    "    <div class=\"class1\" id=\"div1\">\n",
    "      <p class=\"class2\">Visit DataCamp!</p>\n",
    "    </div>\n",
    "    <div class=\"you-are-classy\">\n",
    "      <p class=\"class2\">Keep up the good work!</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# Print out the class of the second div element\n",
    "whats_my_class( html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939617bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Where Am I?\n",
    "\n",
    "# Fill in the blank\n",
    "xpath = '/html/body/div[2]/p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's time to p\n",
    "\n",
    "# Fill in the blank\n",
    "xpath = \"//p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb51bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A classy span\n",
    "\n",
    "# Fill in the blank\n",
    "xpath = \"//span[@class='span-class']\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd16a30",
   "metadata": {},
   "source": [
    "# Xpaths and selectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774318e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Body appendages\n",
    "\n",
    "# Create an XPath string to direct to children of body element\n",
    "xpath = \"/html/body/*\"\n",
    "\n",
    "# Print out the number of elements selected\n",
    "how_many_elements(xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c54729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Datacamp\n",
    "\n",
    "# Create an XPath string to the desired paragraph element\n",
    "xpath = \"/html/body/div[1]/div/p\"\n",
    "\n",
    "# Print out the element text\n",
    "print_element_text(xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8959042b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where its @\n",
    "\n",
    "# Create an Xpath string to select desired p element\n",
    "xpath = '//*[@id=\"div3\"]/p'\n",
    "\n",
    "# Print out selection text\n",
    "print_element_text(xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7508430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your class\n",
    "\n",
    "# Create an XPath string to select p element by class\n",
    "xpath = '//p[@class=\"class-1 class-2\"]'\n",
    "\n",
    "# Print out select text\n",
    "print_element_text(xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35c0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperlink-active\n",
    "\n",
    "# Create an xpath to the href attribute\n",
    "xpath = '//p[@id=\"p2\"]/a/@href'\n",
    "\n",
    "# Print out the selection(s); there should be only one\n",
    "print_attribute(xpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Secret Links\n",
    "\n",
    "# Create an xpath to the href attributes\n",
    "xpath = '//a[contains(@class,\"package-snippet\")]/@href'\n",
    "\n",
    "# Print out how many elements are selected\n",
    "how_many_elements( xpath )\n",
    "\n",
    "# Preview the selected elements\n",
    "preview( xpath )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccba43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X path chaining\n",
    "\n",
    "# Chain together xpath methods to select desired p element\n",
    "sel.xpath('//div').xpath('./span/p[3]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9b137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divy up this exercise\n",
    "\n",
    "from scrapy import Selector\n",
    "\n",
    "# Create a Selector selecting html as the HTML document\n",
    "sel = Selector(text=html)\n",
    "\n",
    "# Create a SelectorList of all div elements in the HTML document\n",
    "divs = sel.xpath('//div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a3915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting a selector\n",
    "\n",
    "# Import a scrapy Selector\n",
    "from scrapy import Selector\n",
    "\n",
    "# Import requests\n",
    "import requests\n",
    "\n",
    "# Create the string html containing the HTML source\n",
    "html = requests.get(url).content\n",
    "\n",
    "# Create the Selector object sel from html\n",
    "sel = Selector(text=html)\n",
    "\n",
    "# Print out the number of elements in the HTML document\n",
    "print(\"There are 1020 elements in the HTML document.\")\n",
    "print(\"You have found: \", len(sel.xpath('//*')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7098845f",
   "metadata": {},
   "source": [
    "# CSS Locators, Chaining and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Xpath to CSS locators\n",
    "\n",
    "# Create the XPath string equivalent to the CSS Locator \n",
    "xpath = '/html/body/span[1]//a'\n",
    "xpath = '//div[@id=\"uid\"]/span//h4'\n",
    "\n",
    "# Create the CSS Locator string equivalent to the XPath\n",
    "css_locator = 'html > body > span:nth-of-type(1) a'\n",
    "css_locator = 'div#uid > span h4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94102e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an a in this course\n",
    "\n",
    "from scrapy import Selector\n",
    "\n",
    "# Create a selector from the html (of a secret website)\n",
    "sel = Selector(text=html)\n",
    "\n",
    "# Fill in the blank\n",
    "css_locator = 'div.course-block > a'\n",
    "\n",
    "# Print the number of selected elements.\n",
    "how_many_elements(css_locator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ea42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CSS Wildcard\n",
    "\n",
    "# Create the CSS Locator to all children of the element whose id is uid\n",
    "css_locator = '*#uid > *'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d62a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You have been href'ed\n",
    "\n",
    "from scrapy import Selector\n",
    "\n",
    "# Create a selector object from a secret website\n",
    "sel = Selector(text=html)\n",
    "\n",
    "# Select all hyperlinks of div elements belonging to class \"course-block\"\n",
    "course_as = sel.css('div.course-block > a')\n",
    "\n",
    "# Selecting all href attributes chaining with css\n",
    "hrefs_from_css = course_as.css('::attr(href)')\n",
    "\n",
    "# Selecting all href attributes chaining with xpath\n",
    "hrefs_from_xpath = course_as.xpath('./@href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c67225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level text\n",
    "\n",
    "# Create an XPath string to the desired text.\n",
    "xpath = '//p[@id=\"p3\"]/text()'\n",
    "\n",
    "# Create a CSS Locator string to the desired text.\n",
    "css_locator = 'p#p3::text'\n",
    "\n",
    "# Print the text from our selections\n",
    "print_results(xpath, css_locator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249800de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All level text\n",
    "\n",
    "  # Create an XPath string to the desired text.\n",
    "xpath = '//p[@id=\"p3\"]//text()'\n",
    "\n",
    "# Create a CSS Locator string to the desired text.\n",
    "css_locator = 'p#p3 ::text'\n",
    "\n",
    "# Print the text from our selections\n",
    "print_results(xpath, css_locator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reveal by response\n",
    "\n",
    "# Get the URL to the website loaded in response\n",
    "this_url = response.url\n",
    "\n",
    "# Get the title of the website loaded in response\n",
    "this_title = response.xpath('//title/text()').extract_first()\n",
    "\n",
    "# Print out our findings\n",
    "print_url_title(this_url, this_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responding with selectors\n",
    "\n",
    "# Create a CSS Locator string to the desired hyperlink elements\n",
    "css_locator = 'a.course-block__link'\n",
    "\n",
    "# Select the hyperlink elements from response and sel\n",
    "response_as = response.css(css_locator)\n",
    "sel_as = sel.css(css_locator)\n",
    "\n",
    "# Examine similarity\n",
    "nr = len(response_as)\n",
    "ns = len(sel_as)\n",
    "for i in range(min(nr, ns, 2)):\n",
    "  print(\"Element %d from response: %s\" % (i+1, response_as[i]))\n",
    "  print(\"Element %d from sel: %s\" % (i+1, sel_as[i]))\n",
    "  print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87c479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting from a selection\n",
    "\n",
    "# Select all desired div elements\n",
    "divs = response.css('div.course-block')\n",
    "\n",
    "# Take the first div element\n",
    "first_div = divs[0]\n",
    "\n",
    "# Extract the text from the (only) h4 element in first_div\n",
    "h4_text = first_div.css('h4::text').extract_first()\n",
    "\n",
    "# Print out the text\n",
    "print(\"The text from the h4 element is:\", h4_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a664ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titular\n",
    "\n",
    "# Create a SelectorList of the course titles\n",
    "crs_title_els = response.css('h4::text')\n",
    "\n",
    "# Extract the course titles \n",
    "crs_titles = crs_title_els.extract()\n",
    "\n",
    "# Print out the course titles \n",
    "for el in crs_titles:\n",
    "  print( \">>\", el )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a736b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping with children\n",
    "\n",
    "# Calculate the number of children of the mystery element\n",
    "how_many_kids = len(mystery.xpath('./*'))\n",
    "\n",
    "# Print out the number\n",
    "print(\"The number of elements you selected was:\", how_many_kids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ffdeef",
   "metadata": {},
   "source": [
    "# Spiders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba61e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inheriting the spider\n",
    "\n",
    "# Import scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the spider class\n",
    "class YourSpider(scrapy.Spider):\n",
    "  name = \"your_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    pass\n",
    "  # parse method\n",
    "  def parse(self, response):\n",
    "    pass\n",
    "  \n",
    "# Inspect Your Class\n",
    "inspect_class(YourSpider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a866691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hurl the urls\n",
    "\n",
    "# Import scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the spider class\n",
    "class YourSpider(scrapy.Spider):\n",
    "  name = \"your_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    urls = [\"https://www.datacamp.com\",\"https://scrapy.org\"]\n",
    "    for url in urls:\n",
    "      yield url\n",
    "  # parse method\n",
    "  def parse(self, response):\n",
    "    pass\n",
    "  \n",
    "# Inspect Your Class\n",
    "inspect_class(YourSpider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Self referencing in classy\n",
    "\n",
    "# Import scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the spider class\n",
    "class YourSpider(scrapy.Spider):\n",
    "  name = \"your_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    self.print_msg(\"Hello World!\")\n",
    "  # parse method\n",
    "  def parse(self, response):\n",
    "    pass\n",
    "  # print_msg method\n",
    "  def print_msg(self, msg):\n",
    "    print(\"Calling start_requests in YourSpider prints out:\", msg)\n",
    "  \n",
    "# Inspect Your Class\n",
    "inspect_class(YourSpider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812cc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting with start requests\n",
    "\n",
    "# Import scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the spider class\n",
    "class YourSpider(scrapy.Spider):\n",
    "  name = \"your_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url=\"https://www.datacamp.com\", callback=self.parse)\n",
    "  # parse method\n",
    "  def parse(self, response):\n",
    "    pass\n",
    "\n",
    "# Inspect Your Class\n",
    "inspect_class(YourSpider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ac8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pen Names\n",
    "\n",
    "# Import the scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the Spider class\n",
    "class DCspider(scrapy.Spider):\n",
    "  name = 'dcspider'\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url = url_short, callback = self.parse)\n",
    "  \n",
    "  # parse method\n",
    "  def parse(self, response):\n",
    "    # Create an extracted list of course author names\n",
    "    author_names = response.css('p.course-block__author-name::text').extract()\n",
    "    # Here we will just return the list of Authors\n",
    "    return author_names\n",
    "  \n",
    "# Inspect the spider\n",
    "inspect_spider(DCspider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crawler Time\n",
    "\n",
    "# Import the scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the Spider class\n",
    "class DCdescr(scrapy.Spider):\n",
    "  name = 'dcdescr'\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url = url_short, callback = self.parse)\n",
    "  \n",
    "  # First parse method\n",
    "  def parse(self, response):\n",
    "    links = response.css('div.course-block > a::attr(href)').extract()\n",
    "    # Follow each of the extracted links\n",
    "    for link in links:\n",
    "      yield response.follow(url = link, callback = self.parse_descr)\n",
    "      \n",
    "  # Second parsing method\n",
    "  def parse_descr(self, response):\n",
    "    # Extract course description\n",
    "    course_descr = response.css('p.course__description::text').extract_first()\n",
    "    # For now, just yield the course description\n",
    "    yield course_descr\n",
    "\n",
    "\n",
    "# Inspect the spider\n",
    "inspect_spider(DCdescr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965846a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to run\n",
    "\n",
    "# Import scrapy\n",
    "import scrapy\n",
    "\n",
    "# Import the CrawlerProcess: for running the spider\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Create the Spider class\n",
    "class DC_Chapter_Spider(scrapy.Spider):\n",
    "  name = \"dc_chapter_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url = url_short,\n",
    "                         callback = self.parse_front)\n",
    "\n",
    "  # First parsing method\n",
    "  def parse_front(self, response):\n",
    "    course_blocks = response.css('div.course-block')\n",
    "    course_links = course_blocks.xpath('./a/@href')\n",
    "    links_to_follow = course_links.extract()\n",
    "    for url in links_to_follow:\n",
    "      yield response.follow(url = url,\n",
    "                            callback = self.parse_pages)\n",
    "  \n",
    "  # Second parsing method\n",
    "  def parse_pages(self, response):\n",
    "    crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "    crs_title_ext = crs_title.extract_first().strip()\n",
    "    ch_titles = response.css('h4.chapter__title::text')\n",
    "    ch_titles_ext = [t.strip() for t in ch_titles.extract()]\n",
    "    dc_dict[crs_title_ext] = ch_titles_ext\n",
    "\n",
    "# Initialize the dictionary **outside** of the Spider class\n",
    "dc_dict = dict()\n",
    "\n",
    "# Run the Spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(DC_Chapter_Spider)\n",
    "process.start()\n",
    "\n",
    "# Print a preview of courses\n",
    "previewCourses(dc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa2da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datacamp descriptions\n",
    "\n",
    "# Import scrapy\n",
    "import scrapy\n",
    "\n",
    "# Import the CrawlerProcess: for running the spider\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Create the Spider class\n",
    "class DC_Description_Spider(scrapy.Spider):\n",
    "  name = \"dc_chapter_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url = url_short,\n",
    "                         callback = self.parse_front)\n",
    "  \n",
    "  # First parsing method\n",
    "  def parse_front(self, response):\n",
    "    course_blocks = response.css('div.course-block')\n",
    "    course_links = course_blocks.xpath('./a/@href')\n",
    "    links_to_follow = course_links.extract()\n",
    "    for url in links_to_follow:\n",
    "      yield response.follow(url = url,\n",
    "                            callback = self.parse_pages)\n",
    "  \n",
    "  # Second parsing method\n",
    "  def parse_pages(self, response):\n",
    "    # Create a SelectorList of the course titles text\n",
    "    crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "    # Extract the text and strip it clean\n",
    "    crs_title_ext = crs_title.extract_first().strip()\n",
    "    # Create a SelectorList of course descriptions text\n",
    "    crs_descr = response.css('p.course__description::text')\n",
    "    # Extract the text and strip it clean\n",
    "    crs_descr_ext = crs_descr.extract_first().strip()\n",
    "    # Fill in the dictionary\n",
    "    dc_dict[crs_title_ext] = crs_descr_ext\n",
    "\n",
    "# Initialize the dictionary **outside** of the Spider class\n",
    "dc_dict = dict()\n",
    "\n",
    "# Run the Spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(DC_Description_Spider)\n",
    "process.start()\n",
    "\n",
    "# Print a preview of courses\n",
    "previewCourses(dc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdef91f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capstone Crawler\n",
    "\n",
    "# Import scrapy\n",
    "import scrapy\n",
    "\n",
    "# Import the CrawlerProcess\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Create the Spider class\n",
    "class YourSpider(scrapy.Spider):\n",
    "  name = 'yourspider'\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url = url_short, callback=self.parse)\n",
    "      \n",
    "  def parse(self, response):\n",
    "    # My version of the parser you wrote in the previous part\n",
    "    crs_titles = response.xpath('//h4[contains(@class,\"block__title\")]/text()').extract()\n",
    "    crs_descrs = response.xpath('//p[contains(@class,\"block__description\")]/text()').extract()\n",
    "    for crs_title, crs_descr in zip( crs_titles, crs_descrs ):\n",
    "      dc_dict[crs_title] = crs_descr\n",
    "    \n",
    "# Initialize the dictionary **outside** of the Spider class\n",
    "dc_dict = dict()\n",
    "\n",
    "# Run the Spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(YourSpider)\n",
    "process.start()\n",
    "\n",
    "# Print a preview of courses\n",
    "previewCourses(dc_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
